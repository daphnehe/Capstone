{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "289c401b-3a2a-41f7-8a06-636650fb51de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/billpark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/billpark/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/billpark/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c84cfe70-2097-49df-bd6d-a40fe8166354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0a07ca4-e038-4a69-a85b-35dfdf92a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load JSON data into a DataFrame\n",
    "def load_json_to_df(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "# List of JSON files\n",
    "json_files = ['HR_prep.json', 'HF_prep.json', 'MR_prep.json', 'MF_prep.json']\n",
    "dfs = []\n",
    "\n",
    "# Load each JSON file into a DataFrame and store them in a list\n",
    "for json_file in json_files:\n",
    "    df = load_json_to_df('data/' + json_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Naming the DataFrames\n",
    "HR_df, HF_df, MR_df, MF_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a67e4f2-4053-4e8a-b4c7-f2236fd53b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18f85dd5-974a-4a3a-8813-d6e24a561fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR = HR_df['preprocessed_text']\n",
    "HF = HF_df['preprocessed_text']\n",
    "MR = MR_df['preprocessed_text']\n",
    "MF = MF_df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e715af34-8c46-466f-befd-41a6f2665f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([HR, HF, MR, MF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77fa235b-02cf-4e43-967d-76655ab1a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assigning labels for each comparison\n",
    "labels_hr_vs_mf = [0] * len(HR) + [1] * len(MF)\n",
    "labels_hf_vs_mf = [0] * len(HF) + [1] * len(MF)\n",
    "labels_mr_vs_mf = [0] * len(MR) + [1] * len(MF)\n",
    "labels_hf_vs_mr = [0] * len(HF) + [1] * len(MR)\n",
    "labels_hr_vs_mr = [0] * len(HR) + [1] * len(MR)\n",
    "labels_hr_vs_hf = [0] * len(HR) + [1] * len(HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acdbbcde-dd38-4114-83d1-17b169b1f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data for each comparison\n",
    "X_train_hr_vs_mf, X_test_hr_vs_mf, y_train_hr_vs_mf, y_test_hr_vs_mf = train_test_split(pd.concat([HR, MF], ignore_index=True), labels_hr_vs_mf, test_size=0.2, random_state=42)\n",
    "X_train_hf_vs_mf, X_test_hf_vs_mf, y_train_hf_vs_mf, y_test_hf_vs_mf = train_test_split(pd.concat([HF, MF], ignore_index=True), labels_hf_vs_mf, test_size=0.2, random_state=42)\n",
    "X_train_mr_vs_mf, X_test_mr_vs_mf, y_train_mr_vs_mf, y_test_mr_vs_mf = train_test_split(pd.concat([MR, MF], ignore_index=True), labels_mr_vs_mf, test_size=0.2, random_state=42)\n",
    "X_train_hf_vs_mr, X_test_hf_vs_mr, y_train_hf_vs_mr, y_test_hf_vs_mr = train_test_split(pd.concat([HF, MR], ignore_index=True), labels_hf_vs_mr, test_size=0.2, random_state=42)\n",
    "X_train_hr_vs_mr, X_test_hr_vs_mr, y_train_hr_vs_mr, y_test_hr_vs_mr = train_test_split(pd.concat([HR, MR], ignore_index=True), labels_hr_vs_mr, test_size=0.2, random_state=42)\n",
    "X_train_hr_vs_hf, X_test_hr_vs_hf, y_train_hr_vs_hf, y_test_hr_vs_hf = train_test_split(pd.concat([HR, HF], ignore_index=True), labels_hr_vs_hf, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dacb089-dbf7-4d25-8e91-ab64bfee6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating TF-IDF vectorizer for each comparison\n",
    "tfidf_vectorizer_hr_vs_mf = TfidfVectorizer(max_features=5000)\n",
    "X_train_hr_vs_mf_tfidf = tfidf_vectorizer_hr_vs_mf.fit_transform(X_train_hr_vs_mf)\n",
    "X_test_hr_vs_mf_tfidf = tfidf_vectorizer_hr_vs_mf.transform(X_test_hr_vs_mf)\n",
    "\n",
    "tfidf_vectorizer_hf_vs_mf = TfidfVectorizer(max_features=5000)\n",
    "X_train_hf_vs_mf_tfidf = tfidf_vectorizer_hf_vs_mf.fit_transform(X_train_hf_vs_mf)\n",
    "X_test_hf_vs_mf_tfidf = tfidf_vectorizer_hf_vs_mf.transform(X_test_hf_vs_mf)\n",
    "\n",
    "tfidf_vectorizer_mr_vs_mf = TfidfVectorizer(max_features=5000)\n",
    "X_train_mr_vs_mf_tfidf = tfidf_vectorizer_mr_vs_mf.fit_transform(X_train_mr_vs_mf)\n",
    "X_test_mr_vs_mf_tfidf = tfidf_vectorizer_mr_vs_mf.transform(X_test_mr_vs_mf)\n",
    "\n",
    "tfidf_vectorizer_hf_vs_mr = TfidfVectorizer(max_features=5000)\n",
    "X_train_hf_vs_mr_tfidf = tfidf_vectorizer_hf_vs_mr.fit_transform(X_train_hf_vs_mr)\n",
    "X_test_hf_vs_mr_tfidf = tfidf_vectorizer_hf_vs_mr.transform(X_test_hf_vs_mr)\n",
    "\n",
    "tfidf_vectorizer_hr_vs_mr = TfidfVectorizer(max_features=5000)\n",
    "X_train_hr_vs_mr_tfidf = tfidf_vectorizer_hr_vs_mr.fit_transform(X_train_hr_vs_mr)\n",
    "X_test_hr_vs_mr_tfidf = tfidf_vectorizer_hr_vs_mr.transform(X_test_hr_vs_mr)\n",
    "\n",
    "tfidf_vectorizer_hr_vs_hf = TfidfVectorizer(max_features=5000)\n",
    "X_train_hr_vs_hf_tfidf = tfidf_vectorizer_hr_vs_hf.fit_transform(X_train_hr_vs_hf)\n",
    "X_test_hr_vs_hf_tfidf = tfidf_vectorizer_hr_vs_hf.transform(X_test_hr_vs_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef4842a1-5373-41fa-9d35-b872824f984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR vs MF:\n",
      "Accuracy: 0.9696601941747572\n",
      "HF vs MF:\n",
      "Accuracy: 0.9608323133414932\n",
      "MR vs MF:\n",
      "Accuracy: 0.9400363416111448\n",
      "HF vs MR:\n",
      "Accuracy: 0.9170199878861296\n",
      "HR vs MR:\n",
      "Accuracy: 0.8774774774774775\n",
      "HR vs HF:\n",
      "Accuracy: 0.7779126213592233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Function to train and evaluate an XGBoost model\n",
    "def train_and_evaluate_xgb(X_train, y_train, X_test, y_test):\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "# Using the function to train and evaluate models for each comparison\n",
    "print(\"HR vs MF:\")\n",
    "train_and_evaluate_xgb(X_train_hr_vs_mf_tfidf, y_train_hr_vs_mf, X_test_hr_vs_mf_tfidf, y_test_hr_vs_mf)\n",
    "print(\"HF vs MF:\")\n",
    "train_and_evaluate_xgb(X_train_hf_vs_mf_tfidf, y_train_hf_vs_mf, X_test_hf_vs_mf_tfidf, y_test_hf_vs_mf)\n",
    "print(\"MR vs MF:\")\n",
    "train_and_evaluate_xgb(X_train_mr_vs_mf_tfidf, y_train_mr_vs_mf, X_test_mr_vs_mf_tfidf, y_test_mr_vs_mf)\n",
    "print(\"HF vs MR:\")\n",
    "train_and_evaluate_xgb(X_train_hf_vs_mr_tfidf, y_train_hf_vs_mr, X_test_hf_vs_mr_tfidf, y_test_hf_vs_mr)\n",
    "print(\"HR vs MR:\")\n",
    "train_and_evaluate_xgb(X_train_hr_vs_mr_tfidf, y_train_hr_vs_mr, X_test_hr_vs_mr_tfidf, y_test_hr_vs_mr)\n",
    "print(\"HR vs HF:\")\n",
    "train_and_evaluate_xgb(X_train_hr_vs_hf_tfidf, y_train_hr_vs_hf, X_test_hr_vs_hf_tfidf, y_test_hr_vs_hf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8087e66-97e2-4a1f-aaf8-7fb0c70b68bd",
   "metadata": {},
   "source": [
    "Word2Vec attemp from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dffec04-0d2a-44f3-bbb5-ff6780e64d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2e7bc36-a405-44fe-9b95-1a91c9cc94c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/billpark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy for Human Real vs AI Fake: 0.956311\n",
      "XGBoost Accuracy for Human Fake vs AI Fake: 0.925337\n",
      "XGBoost Accuracy for AI Real vs AI Fake: 0.910357\n",
      "XGBoost Accuracy for Human Fake vs AI Real: 0.898243\n",
      "XGBoost Accuracy for Human Real vs AI Real: 0.807808\n",
      "XGBoost Accuracy for Human Real vs Human Fake: 0.788835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def text_to_wordlist(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def build_word2vec_model(data_frames, text_extractor):\n",
    "    sentences = []\n",
    "    for df in data_frames:\n",
    "        if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "            for _, row in df.iterrows():\n",
    "                extracted_text = text_extractor(row)\n",
    "                tokenized_text = text_to_wordlist(extracted_text)\n",
    "                sentences.append(tokenized_text)\n",
    "        else:\n",
    "            print(\"Error: Provided data is not a DataFrame or is empty.\")\n",
    "\n",
    "    if sentences:\n",
    "        model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(\"No sentences were extracted for Word2Vec training. Check your data and text extraction logic.\")\n",
    "\n",
    "def vectorize_with_word2vec(df, word2vec_model, text_extractor):\n",
    "    def average_vector(row):\n",
    "        text = text_extractor(row)\n",
    "        words = text_to_wordlist(text)\n",
    "        word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "        if len(word_vectors) == 0:\n",
    "            return np.zeros(word2vec_model.vector_size)\n",
    "        else:\n",
    "            return np.mean(word_vectors, axis=0)\n",
    "    return np.vstack(df.apply(average_vector, axis=1))\n",
    "\n",
    "def prepare_and_vectorize_data(df1, df2, word2vec_model, text_extractor):\n",
    "    labels = [0] * len(df1) + [1] * len(df2)\n",
    "    X = pd.concat([df1, df2], ignore_index=True)\n",
    "    X_vectors = vectorize_with_word2vec(X, word2vec_model, text_extractor)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectors, labels, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_xgb(X_train, y_train, X_test, y_test, comparison_name):\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"XGBoost Accuracy for {comparison_name}: {accuracy:.6f}\")\n",
    "\n",
    "# Assuming HR_df, HF_df, MR_df, MF_df are DataFrame objects and are loaded correctly\n",
    "word2vec_model = build_word2vec_model([HR_df, HF_df, MR_df, MF_df], lambda row: extract_text(row, 'preprocessed_text', 'text'))\n",
    "\n",
    "# Define pairs for comparison\n",
    "pairs = [\n",
    "    (HR_df, MF_df, \"Human Real vs AI Fake\"),\n",
    "    (HF_df, MF_df, \"Human Fake vs AI Fake\"),\n",
    "    (MR_df, MF_df, \"AI Real vs AI Fake\"),\n",
    "    (HF_df, MR_df, \"Human Fake vs AI Real\"),\n",
    "    (HR_df, MR_df, \"Human Real vs AI Real\"),\n",
    "    (HR_df, HF_df, \"Human Real vs Human Fake\")\n",
    "]\n",
    "\n",
    "for df1, df2, name in pairs:\n",
    "    X_train, X_test, y_train, y_test = prepare_and_vectorize_data(df1, df2, word2vec_model, lambda row: extract_text(row, 'preprocessed_text', 'text'))\n",
    "    train_and_evaluate_xgb(X_train, y_train, X_test, y_test, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf9ad4-f9fe-4943-881a-7c436d12f04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
